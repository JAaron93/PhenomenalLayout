# Dolphin Implementation Plan

## Overview

This document outlines the implementation plan for integrating ByteDance's Dolphin document parsing model with our existing translation pipeline, replacing the current PyMuPDF-based approach with superior document understanding capabilities.

## Current State Analysis

### Existing Architecture
- **Text Extraction**: PyMuPDF with image-text overlay technique
- **Translation Services**: Lingo.dev API with high-performance parallel processing
- **Format Preservation**: High-resolution rendering (300 DPI) with precise text positioning
- **Supported Formats**: PDF, DOCX, TXT

### Limitations of Current Approach
- Limited to extracting existing text, no OCR capabilities
- Struggles with scanned documents or images with embedded text
- Complex layout understanding is limited to bbox positioning

## Dolphin Model Capabilities

### Key Features
- **Advanced Document Understanding**: Two-stage analyze-then-parse paradigm
- **OCR Capabilities**: Handles scanned documents and images with text
- **Layout Intelligence**: Understands complex document structures (tables, figures, formulas)
- **Natural Reading Order**: Maintains proper document flow
- **Structured Output**: Provides both JSON and Markdown formats

### Technical Specifications
- **Architecture**: Vision-encoder-decoder with Swin Transformer + MBart
- **Size**: 398M parameters
- **License**: MIT
- **Languages**: Multi-language support (Chinese, English, etc.)

## Implementation Strategy

### Option 1: Hugging Face Spaces API (Selected)

**Approach**: Utilize ByteDance's existing Dolphin Space via API calls
- **Endpoint**: `https://huggingface.co/spaces/ByteDance/Dolphin`
- **Benefits**:
  - Leverages optimized inference setup
  - No local GPU requirements
  - Cost-effective with existing $25 HF credits
  - Maintained by ByteDance team

## Revised Architecture Plan

### Phase 1: Dolphin Integration Service

Create new service module:

```python
# services/dolphin_service.py
class DolphinProcessor:
    def __init__(self, hf_token: str):
        self.hf_token = hf_token
        self.spaces_url = "https://huggingface.co/spaces/ByteDance/Dolphin"
        self.session = requests.Session()

    def extract_document_structure(self, document_image: bytes) -> dict:
        """
        Extract structured content from document image using Dolphin
        Returns: {
            'markdown': str,  # Structured markdown representation
            'json': dict,     # Detailed layout information
            'elements': list  # Individual document elements
        }
        """
        raise NotImplementedError(
            "extract_document_structure must call the HF Spaces endpoint and "
            "return a dict with keys: markdown, json, elements"
        )

    def process_pdf_pages(self, pdf_path: str) -> list:
        """Process all pages of a PDF document"""
        raise NotImplementedError(
            "process_pdf_pages must convert each PDF page to an image and "
            "call extract_document_structure for every page"
        )

### Phase 2: Enhanced Document Processor
class EnhancedDocumentProcessor:
    def __init__(self, hf_token: str | None = None):
        if hf_token is None:
            # Allow injection via env var as a sane default
            hf_token = os.getenv("HF_TOKEN")
        if not hf_token:
            raise ValueError("Hugging Face token not provided")
        self.dolphin = DolphinProcessor(hf_token)
        # Remove PyMuPDF dependencies
class EnhancedDocumentProcessor:
    def __init__(self):
        self.dolphin = DolphinProcessor(hf_token)
        # Remove PyMuPDF dependencies

    def extract_content(self, file_path: str) -> dict:
        """
        Extract content using Dolphin for superior format preservation
        """
        # 1. Convert PDF pages to high-res images
        # 2. Send to Dolphin for structure extraction
        # 3. Return structured content with enhanced layout info
        pass
```

### Phase 3: Translation Workflow Integration

Enhanced translation pipeline:

1. **Document â†’ Images**: Convert PDF pages to optimized images
2. **Dolphin Processing**: Extract structured text + layout via HF Spaces API
3. **Translation**: Use Lingo.dev API with parallel processing on extracted text
4. **Reconstruction**: Rebuild document using Dolphin's superior layout understanding

### Phase 4: Implementation Steps

#### Step 1: Dependencies Update
- Remove PyMuPDF from `requirements.txt`
- Add `pdf2image` for PDF to image conversion
- Add `Pillow` for image processing
- Update `huggingface_hub` for API interactions

#### Step 2: Service Integration
- Create `services/dolphin_service.py`
- Modify `services/enhanced_document_processor.py`
- Update `app.py` to use new processing pipeline

#### Step 3: API Configuration
- Add Hugging Face token to environment variables
- Configure Dolphin Spaces API endpoints
- Implement authentication and error handling

#### Step 4: Cost Optimization
- **Batch Processing**: Process multiple pages per API call
- **Caching**: Store Dolphin results to avoid reprocessing
- **Smart Preprocessing**: Optimize image quality vs. processing cost
- **Progress Tracking**: Monitor credit usage in real-time

## Key Advantages Over Current Approach

### Superior Document Understanding
- **OCR Capabilities**: Handles scanned documents and images with text
- **Layout Intelligence**: Better understanding of complex document structures
- **Natural Reading Order**: Maintains proper document flow
- **Element Recognition**: Distinguishes between text, figures, tables, formulas

### Enhanced Format Preservation
- **Structured Output**: JSON + Markdown formats ideal for reconstruction
- **Element Relationships**: Understands how document elements relate
- **Semantic Understanding**: Goes beyond simple bbox positioning

### Operational Benefits
- **No Local GPU**: Leverages HF's optimized infrastructure
- **Scalability**: Handles varying document complexity
- **Maintainability**: Reduced local dependencies
- **Cost Efficiency**: $25 credits sufficient for extensive testing

## Cost Management Strategy

### Credit Optimization
- **Efficient Image Processing**: Optimize resolution vs. quality trade-offs
- **Batch Operations**: Group multiple pages for processing
- **Caching Strategy**: Store processed results to avoid reprocessing
- **Usage Monitoring**: Track API calls and credit consumption

### Budget Allocation
- **$25 Credits**: Sufficient for extensive testing and initial production
- **Testing Phase**: ~$5-10 for comprehensive testing
- **Production Phase**: ~$15-20 for initial deployment
- **Monitoring**: Real-time usage tracking via HF dashboard

## Migration Path

### Phase 1: Parallel Implementation
- Keep existing PyMuPDF pipeline functional
- Implement Dolphin pipeline alongside
- A/B testing for quality comparison

### Phase 2: Gradual Transition
- Start with simple documents for Dolphin
- Expand to complex documents as confidence grows
- Maintain fallback options during transition

### Phase 3: Full Migration
- Replace PyMuPDF pipeline completely
- Remove unused dependencies
- Optimize for Dolphin-based processing

## Success Metrics

### Quality Metrics
- **Text Extraction Accuracy**: Compare OCR quality vs. current approach
- **Layout Preservation**: Measure format retention in translated documents
- **Processing Speed**: API response times vs. local processing
- **Error Rates**: Track API failures and recovery

### Operational Metrics
- **Credit Usage**: Monitor cost per document processed
- **Processing Throughput**: Documents processed per hour
- **User Satisfaction**: Quality of translated documents
- **System Reliability**: Uptime and error handling

## Risk Mitigation

### Technical Risks
- **API Availability**: Monitor HF Spaces uptime
- **Rate Limiting**: Implement proper request throttling
- **Error Handling**: Robust fallback mechanisms
- **Data Privacy**: Ensure secure document transmission

### Business Risks
- **Cost Overruns**: Careful credit monitoring and budget alerts
- **Quality Regression**: Comprehensive testing before full deployment
- **Vendor Lock-in**: Maintain flexibility for future alternatives

## Timeline Estimate

- **Week 1-2**: Service integration and basic API connectivity
- **Week 3-4**: Enhanced document processor implementation
- **Week 5-6**: Translation workflow integration and testing
- **Week 7-8**: Optimization, monitoring, and production deployment

## Conclusion

The integration of Dolphin via Hugging Face Spaces API represents a significant upgrade to our document processing capabilities. By leveraging Dolphin's superior document understanding while maintaining our existing translation services, we can provide better format preservation, OCR capabilities, and overall document quality.

The approach is cost-effective, technically sound, and provides a clear path for enhanced document translation services while utilizing existing Hugging Face credits efficiently.
